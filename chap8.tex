%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Infrastructure}

This chapter aims to describe the tools and processes involved in the infrastructure setup. From local development environment to the set of production servers running the Redch. Firstly, it explains the infrastructure setup and secondly, it describes the provisioning and deployment processes.

\section{Amazon AWS setup}

Amazon Web Services (AWS) is a cloud computing platform. It offers a collection of remote computing services ranging from computing and storage to networking services such as DNS, among others. AWS is a world-wide leader of Infrastructure-as-a-Service (IaaS) providers with numerous companies like Spotify, Heroku, Airbnb, Foursquare, Github, Reddit or Mapbox relying on them.

The whole infrastructure of the system is compound by EC2 instances, virtual servers in Amazon's cloud. They all run a custom Amazon Machine Image (AMI) built from a raw Ubuntu 12.04 LTS with all needed dependencies ---Puppet and Ruby 2.0.0--- installed. As a result, any new instance booted up with this custom AMI is ready to be provisioned. Starting and stopping machines, as well as configuring their firewall rules is managed through the AWS Management Console, a web UI.

One of the major benefits Redch can take advantage of is Amazon's Auto Scaling. This service allows to scale the capacity of the EC2 instances up and down according to a set of predefined conditions. A load balancer, for instance, can automatically spawn app servers during demand spikes and shut them down during low demand periods. Redch can get the most out of it exploiting the fact that solar panels don't produce energy at night, thereby minimizing costs. Likewise, less computing power is required under windless conditions.

As for the database server, although it would desirable to keep the infrastructure provider-independent, Amazon RDS has been chosen. It makes easier to set up, operate, and scale a relational database. Furthermore, it provides automated backups, Multi-AZ replication and monitoring metrics. It has support for MySQL, Oracle, SQL Server and PostrgeSQL, all the DBMSs supported by 52ºNorth SOS, being the latter the one it uses by default. However, the PostrgeSQL support is still in beta version due to its recent release in November of 2013.

The final production environment comprehends the four servers shown in \ref{fig:infrastructure}. Three EC2 micro instances plus a RDS micro instance. All three EC2 instances are attached to an Elastic Block Storage (EBS), which are storage volumes with built-in redundancy. These volumes host the filesystem of their related EC2 instances, each one selected with 8GB of storage space.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{infrastructure}
  \caption{Production's infrastructure diagram}
  \label{fig:infrastructure}
\end{figure}

Ubuntu 12-04 LTS has been chosen as the OS of all three servers due to its stability and security besides, the inherent benefits of a Linux OS. With regard to the database, Amazon's RDS abstract away from the particularities of the underlying hardware by providing the database access as a service.

\section{Configuration Management}

Once the software is developed the underlying infrastructure must be configured to host each of the system components. This process, that involves creating directories and installing packages, may be error-prone when done manually. Besides, it may need to be repeated several times when new servers need to be set up. Even though writing down the build-out process may help, whoever reads that documentation can't figure out the current state of the configuration.

Server automation frameworks formalize systems administration treating infrastructure as code. As a result, infrastructure's configuration can be tested and repeated, automating away repetitive tasks while systems administrators focus on architecting and tunning services.

Puppet, among other solutions such as Chef, enables server configuration automation. It automates server provisioning by formalizing its configuration into manifests. Puppet's manifests are text files that contain statements written in a declarative domain-specific language (DSL) that allows to define the desired state of the infrastructure. Once these configurations are deployed, Puppet automatically installs the necessary packages and ensures that the machine’s files and services match the desired state.

\begin{listing}[h]
\begin{minted}[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
] {puppet}
package { 'apache2':
  provider => 'apt',
  ensure   => 'installed'
}

service { 'apache2':
  ensure => 'running'
}
\end{minted}
\caption{Example of Puppet's manifest file}
\label{fig:puppet}
\end{listing}

Puppet is mature and widely used. Besides having an open source version, there are lots of learning materials available online.

\section{Provisioning}

Prior provisioning any server must have puppet installed, which comes packaged as a ruby gem. Therefore, Puppet does also require a MRI Ruby interpreter. Puppet can be installed with any system package manager, doing so will likely install previous releases missing features and bug fixes.

Puppet allows to provision machines by either applying the configuration directly or compiled into a catalog and distributed to the target system via client-server paradigm.

\section{Deployment}

Once the configuration is applied the target server is up and ready. Next, the code release must be transferred to the production environment to make the application available for use.