%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Conclusions}

\section{Conclusions}

The myriad of open-source software and modern web technologies used in this MS Thesis have provided to be a viable solution for building IT infrastructure for public research centers. Specifically, these technologies have been combined together to build a distributed as a proof-of-concept for a larger initiative, which aims to provide a valuable insight into the actual production of renewable energies at a small scale in Catalonia.

The introduction presents the motivations behind this initiative of the CREAF and outlines the main goals of this project.

Next, a thorough analysis defines the boundaries of this thesis by providing its scope and requirements. This is detailed further in Chapter 3 with a formal specification of the use cases and the whole conceptual model around the measurement and processing of observations.

Then, Chapter 4 details the findings of the deep research process that had been carried out 
to later support the design decisions taken in Chapter 5. These chapters are particularly relevant due to the fact the chosen technologies are the basis for its further development.

Chapters 6 and 7 provide insight into the implementation and the infrastructure the system runs on. Particular attention is given to the automation of common processes such as provisioning, deployment and maintenance tasks, which provide reliability and confidence to the system's managers. Then, the evaluation of the resulting system in terms of performance is described in Chapter 8.

In spite of the difficulties that determining the scope of the product entailed, the final delimitation we came up with together with CREAF has proven to be adequate. It has been enough to explore each individual part of the project and demonstrate their potential. Specifically, although being rather simple the web application shows how a data visualization can be enriched with a full-featured application. As for the future sensors, the development of the simulator has allowed to better understand the challenges and requirements their design may involve.

On the other hand, the key point of using a messaging queue has been a very successful decision, in that has enabled a loosely coupled and scalable architecture that allows both ends of the queue, the SOS and the web application, to evolve independently. But as downside, this has brought some complexity that affects the resilience of the system. Implementing a more robust redundancy-based resilience mechanism would have improved the overall quality of the system.

As for the infrastructure, the complexity of setting the servers up surpassed the initial estimation causing a great impact on the time invested for that matter. While running the services in a development environment is often very easy, there are numerous variables involved when it comes to a production environment. Furthermore, it was the least-known of the fields involved in the project and the one that required the deepest understanding of the architecture. This led us to the conclusions that being the infrastructure critical for the proper functioning of the system, much attention has to be paid to the administration of the system. Otherwise, its impact on cost will increase as it evolves.

Regarding the methodology, the outcome of the iterative development is a clean and maintainable codebase. A first iteration laid out each component and allowed to get the insight upon which the second iteration improved them so as to be up and ready.

Finally, all the goals of the project have been successfully achieved and all the requirements in Chapter 2 were met. We are able to simulate sensors with a command line interface and the observations are stored, processed and displayed in real time.

\section{Further Work}

Considering the current state of the product, we identify some unresolved issues and steps that would be worth exploring in further research.

From the point of view of the implementation, there are a couple of aspects of the current architecture that would be interesting to investigate. First, given the event-driven nature of the web application's  back-end, it may be worth replacing its implementation with Node.js. Its non-blocking I/O design that claims to maximize throughput and efficiency, makes it suitable for scalable networking applications. This seems to be a natural fit the features of this project and may even surpass the EventMachine's high performance. However, it has not been possible due to the time constraints considering our total lack of awareness of this platform.

Regarding the messaging queue, given that RabbitMQ's messages acknowledgement is not used may be beneficial to implement messaging with Redis instead. It is essentially a very high-performance key/value store for structured data that brings many other features such as pub/sub capabilities. This, however, doesn't include message acknowledgement for the sake of performance. Replacing RabbitMQ with Redis would enable to implement retrieval of latest observations once a new browser connection is established, feature that isn't currently supported. Nevertheless, Redis pub/sub simplicity compared to RabbitMQ queue features may impact on future decisions as the system's usage grows.

From the infrastructure perspective, it may be beneficial at the early stages of the project to lean towards a PaaS hosting rather than the current IaaS. As a result, it would require far less systems administration knowledge and it would simplify deployments even more, but this comes at the expense of higher cost and less control over the product. In any case, this a possibility that is worth studying.

Finally, as next step of the project the system's poor performance must be addressed by switching to more reliable and powerful servers. After that, it would be recommended to start using the system with a small subset of real users while the ideas exposed above are considered prior to a public release. Meanwhile it would be valuable to look for the involvement of public institutions, other research centers and specially the Open Geospatial Consortium so as to ensure the success of the project.